

Terminology :
    Tokenization : Dividing a much complex item in simpler possible item according to the necessity
        character tokenizer : 
            "the cat sat on the mat" -->> 
            ["T","h","e"," ","c","a","t"," ","s","a","t"," ","o","n"," ","t","h","e"," ","m","a","t","."]
        subword tokenizer :
            "unbelievable"
            ["un", "believe", "able"]
        Word tokenizer :

        sentence tokenizer

        Example tokenizers : BPE(Byte pair encoding) , Auto Tokenizer from transformers library hugging face

    Embedding :
        Word embeddings Examples :
            Word2Vec
            Glove
            FastText
        Sentence embeddings :
            BERT
            Sentence BERT
            Universal sentence encoder
        Vector embedding : (used for images or sounds or anything that needs to be embedded)
    Lemmatization
    stemming
    Positional encoding : I think it numerically represents the sequence in which the prompt text was given
        "the cat sat" is given , if PE is not there "sat the cat" could be interpreted for futher steps 
    POS tagging
    Name entity recognition and relation
    chunking
    stop word removal



Attention mapping of words in a sentence to each other 


Foundational models :(Subject to correction)
    BERT 
    GPT
    LLaMa
    BLOOM
    FLAN-T5
    PaLM


Day 4 12:28 starting 



MCP - MODEL CONTEXT PROTOCOL