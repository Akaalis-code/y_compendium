Spark RAPIDS Accelerator --> for Spark to use GPU computing

Python bindings are interfaces that allow Python code to interact with libraries written in other programming languages, such as C or C++

Q)  If pyspark is just a API library whose actual executables are present in APACHE SPARK BINARIES , then how is pyspark
    working properly without installing APACHE SPARK.
A)  I think pyspark does come with light weight SPARK BINARIES enough to execute PYSPARK APIS without any 
    cluster management part 


Clean later -->> Spark analogy pt in this file is 7 MB try reducing the size later /home/yvm/Documents/y_youtube/y_youtube_teaching/y_pyspark/y_pyspark_batch.md





---------------------------------------- Various tools -- start -------------------------------------------------------------

PCB WAY -->> for 3d printing , CNC cutting PCB 
    In PCB manufacturing there are few ways of creation
        SMT - Surface mount technology
        THT - Through hole technology 
        HDI - High density interconnect
        BGA - Ball grid array


Video Editing :
    PICSART web based tool for AI enhaced removals 
    
---------------------------------------- Various tools -- start -------------------------------------------------------------