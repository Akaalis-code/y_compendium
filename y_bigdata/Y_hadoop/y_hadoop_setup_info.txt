################################# 1) SOFTWARES NEEDED ## START ###########################################################

1) Download Hadoop from official website and extract it
2) Install Java ( Check the allowed versions of java for your hadoop version )
3) Install SSH tool 
		sudo apt install openssh-server
		sudo apt install openssh-client
4) Setup ssh for your local host
		ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
		cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
		chmod 0600 ~/.ssh/authorized_keys

	
	

################################# 1) SOFTWARES NEEDED ## End ###########################################################







################################# 2) Hadoop Config files setup ## START ###########################################################

You have to give configuration infomation that fits your project in below files
	1) core-site.xml
	2) hdfs-site.xml
	3) mapred-site.xml
	4) yarn-site.xml
	5) Workers file

We have default files for all the above files too in various locations , To find them out use below command
	<find /home/yv1/hadoop-3.3.6 -name *-default.xml>    ( Without <> )




1) core-site.xml
	
	Add following block in the file inside configuration block 
	(Note : "fs.default.name" property has been changed to "fs.defaultFS")
	
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://localhost:9000</value>
	</property>
	


2) hdfs-site.xml

	Add following block in the file inside configuration blocK

    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>/home/yv1/y_my_hadoop_directories/y_my_namenode</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>/home/yv1/y_my_hadoop_directories/y_my_datanode</value>
	</property>



3) mapred-site.xml

	Add following block in the file inside configuration blocK

	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
	<property>
        <name>mapreduce.application.classpath</name>
        <value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
    </property>


4) yarn-site.xml

	Add following block in the file inside configuration blocK

	<property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME</value>
    </property>


5) Workers 

	Add "localhost"
################################# 2) Hadoop Config files setup ## End ###########################################################








################################# 3) Env variables setup ## start ###########################################################

1) .bashrc file ---> Inside this file Add below items in the very end

		export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
		export HADOOP_HOME=/home/yv1/hadoop-3.3.6
		export HADOOP_COMMON_HOME=$HADOOP_HOME
		export HADOOP_HDFS_HOME=$HADOOP_HOME
		export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
		export HADOOP_YARN_HOME=$HADOOP_HOME
		export HADOOP_MAPRED_HOME=$HADOOP_HOME
		export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$JAVA_HOME/bin



2) After adding above elements save file and run below command in terminal to have these variables take effect

		source ~/.bashrc 


3) hadoop-env.sh

		export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64


################################# 3) Env variables setup ## End ###########################################################








################################# 4) Start or stop services and monitor ## Start ####################################################


################################# 4) Start or stop services and monitor ## End ####################################################
